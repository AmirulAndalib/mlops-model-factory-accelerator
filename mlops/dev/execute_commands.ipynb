{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a standalone notebook, used for development purposes\n",
    "\n",
    "This is a sample notebook to execute a command in the AML workspace. This notebook can be used for development purposes by the Data scientists, to try out their experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup variables\n",
    "\n",
    "subscription_id = \"\"\n",
    "resource_group_name = \"\"\n",
    "workspace_name = \"\"\n",
    "\n",
    "# compute related variables\n",
    "cluster_name = \"\"\n",
    "cluster_size = \"\"\n",
    "cluster_region = \"\"\n",
    "min_instances = 0\n",
    "max_instances = 0\n",
    "idle_time_before_scale_down = 0\n",
    "\n",
    "# environment related variables\n",
    "env_base_image_name = \"\"\n",
    "conda_path = \"\"\n",
    "environment_name = \"\"\n",
    "description = \"\"\n",
    "\n",
    "#command related\n",
    "experiment_name = \"\"\n",
    "display_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup_secrets\n",
    "\n",
    "# use `load_env` and define a sample .env template to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages\n",
    "\n",
    "%pip install azure-ai-ml==1.7.2\n",
    "%pip install azure-identity==1.13.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a compute, or get a compute if already exists to run the command\n",
    "\n",
    "The following block of code will help in creating a compute instance within the AML workspace. If the workspace already has a compute instance, it will return the existing compute instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "def create_or_get_compute():\n",
    "    compute_object = None\n",
    "    try:\n",
    "        client = MLClient(\n",
    "            DefaultAzureCredential(),\n",
    "            subscription_id=subscription_id,\n",
    "            resource_group_name=resource_group_name,\n",
    "            workspace_name=workspace_name,\n",
    "        )\n",
    "        try:\n",
    "            compute_object = client.compute.get(cluster_name)\n",
    "            print(f\"Found existing compute target {cluster_name}, so using it.\")\n",
    "        except:\n",
    "            print(f\"{cluster_name} is not found! Trying to create a new one.\")\n",
    "            compute_object = AmlCompute(\n",
    "                name=cluster_name,\n",
    "                type=\"amlcompute\",\n",
    "                size=cluster_size,\n",
    "                location=cluster_region,\n",
    "                min_instances=min_instances,\n",
    "                max_instances=max_instances,\n",
    "                idle_time_before_scale_down=idle_time_before_scale_down,\n",
    "            )\n",
    "            compute_object = client.compute.begin_create_or_update(\n",
    "                compute_object\n",
    "            ).result()\n",
    "            print(f\"A new cluster {cluster_name} has been created.\")\n",
    "    except Exception as ex:\n",
    "        print(\"Oops!  invalid credentials.. Try again...\")\n",
    "        raise\n",
    "    return compute_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an environment, or get an environment\n",
    "\n",
    "The following block of code will help in creating an environment within the AML workspace. If the workspace already has a environment, it will return the existing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "def create_or_get_environment():\n",
    "    try:\n",
    "        print(f\"Checking {environment_name} environment.\")\n",
    "        client = MLClient(\n",
    "            DefaultAzureCredential(),\n",
    "            subscription_id=subscription_id,\n",
    "            resource_group_name=resource_group_name,\n",
    "            workspace_name=workspace_name,\n",
    "        )\n",
    "        env_docker_conda = Environment(\n",
    "            image=env_base_image_name,\n",
    "            conda_file=conda_path,\n",
    "            name=environment_name,\n",
    "            description=description,\n",
    "        )\n",
    "        environment = client.environments.create_or_update(env_docker_conda)\n",
    "        print(f\"Environment {environment_name} has been created or updated.\")\n",
    "        return environment\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\n",
    "            \"Oops! invalid credentials or error while creating ML environment.. Try again...\"\n",
    "        )\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_prep.py\n",
    "import argparse\n",
    "\n",
    "def main(raw_data_path, prep_data_path):\n",
    "    print(f\"function to process raw data from: {raw_data_path} and prep data from: {prep_data_path}\")\n",
    "    # perform the data prep activity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--raw_data_path\", type=str, default=\"../data/raw_data\", help=\"Path to raw data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--prep_data_path\", type=str, default=\"../data/prep_data\", help=\"Path to prep data\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    main(args.raw_data_path, args.prep_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a command job\n",
    "\n",
    "from azure.ai.ml import command\n",
    "\n",
    "def create_command(environment):\n",
    "    command_job = command(\n",
    "            experiment_name=experiment_name,\n",
    "            display_name=display_name,\n",
    "            code=\"./\",\n",
    "            command=\"python prep_data.py --raw_data ../data/raw_data --prep_data ../data/prep_data\",\n",
    "            environment=environment,\n",
    "            compute=cluster_name,\n",
    "            environment_variables={\n",
    "                \"ENV_VARIABLES_FOR_COMMAND\": \"\"\n",
    "            }\n",
    "        )\n",
    "    return command_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for the command job to finish\n",
    "\n",
    "import time\n",
    "\n",
    "def wait_for_job_to_finish(\n",
    "    ml_client, \n",
    "    pipeline_job\n",
    "):\n",
    "    total_wait_time = 21600\n",
    "    current_wait_time = 0\n",
    "    job_status = [\n",
    "        \"NotStarted\",\n",
    "        \"Queued\",\n",
    "        \"Starting\",\n",
    "        \"Preparing\",\n",
    "        \"Running\",\n",
    "        \"Finalizing\",\n",
    "        \"Provisioning\",\n",
    "        \"CancelRequested\",\n",
    "        \"Failed\",\n",
    "        \"Canceled\",\n",
    "        \"NotResponding\",\n",
    "    ]\n",
    "\n",
    "    while pipeline_job.status in job_status:\n",
    "        if current_wait_time <= total_wait_time:\n",
    "            time.sleep(20)\n",
    "            pipeline_job = ml_client.jobs.get(pipeline_job.name)\n",
    "\n",
    "            current_wait_time = current_wait_time + 15\n",
    "\n",
    "            if (\n",
    "                pipeline_job.status == \"Failed\"\n",
    "                or pipeline_job.status == \"NotResponding\"\n",
    "                or pipeline_job.status == \"CancelRequested\"\n",
    "                or pipeline_job.status == \"Canceled\"\n",
    "            ):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if (\n",
    "        pipeline_job.status == \"Completed\"\n",
    "        or pipeline_job.status == \"Finished\"\n",
    "    ):\n",
    "        print(\"job completed\")\n",
    "    else:\n",
    "        print(\"Exiting job with failure\")\n",
    "        raise Exception(\"Sorry, exiting job with failure..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orchestrate !!\n",
    "\n",
    "# get_compute\n",
    "# get_environment\n",
    "# command job\n",
    "# wait for the command job to get over. (optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
